{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c9e15dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "42fe77c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/global/u1/p/pr4santh/Projects/SYMBA_SSM\n"
     ]
    }
   ],
   "source": [
    "cd /global/homes/p/pr4santh/Projects/SYMBA_SSM/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc151c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c2142b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from collections import defaultdict\n",
    "from typing import Dict, Optional, Union\n",
    "\n",
    "def count_parameters(model: nn.Module,\n",
    "                    trainable_only: bool = False,\n",
    "                    detailed: bool = False) -> Union[int, Dict[str, int]]:\n",
    "    \"\"\"\n",
    "    Count the number of parameters in a PyTorch model and its submodules.\n",
    "\n",
    "    Args:\n",
    "        model: PyTorch model (nn.Module)\n",
    "        trainable_only: If True, count only trainable parameters (default: False)\n",
    "        detailed: If True, return detailed breakdown by submodule (default: False)\n",
    "\n",
    "    Returns:\n",
    "        int: Total number of parameters (if detailed=False)\n",
    "        Dict[str, int]: Parameter counts by submodule (if detailed=True)\n",
    "    \"\"\"\n",
    "\n",
    "    if detailed:\n",
    "        param_counts = defaultdict(int)\n",
    "\n",
    "        # Count parameters for each named module\n",
    "        for name, module in model.named_modules():\n",
    "            module_name = name if name else \"root\"\n",
    "\n",
    "            for param in module.parameters(recurse=False):  # Don't double count\n",
    "                if not trainable_only or param.requires_grad:\n",
    "                    param_counts[module_name] += param.numel()\n",
    "\n",
    "        # Convert to regular dict and sort by parameter count\n",
    "        param_counts = dict(sorted(param_counts.items(),\n",
    "                                 key=lambda x: x[1], reverse=True))\n",
    "        return param_counts\n",
    "\n",
    "    else:\n",
    "        # Simple total count\n",
    "        if trainable_only:\n",
    "            return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "        else:\n",
    "            return sum(p.numel() for p in model.parameters())\n",
    "\n",
    "\n",
    "def print_parameter_summary(model: nn.Module,\n",
    "                          trainable_only: bool = False,\n",
    "                          show_details: bool = True):\n",
    "    \"\"\"\n",
    "    Print a formatted summary of model parameters.\n",
    "\n",
    "    Args:\n",
    "        model: PyTorch model\n",
    "        trainable_only: If True, count only trainable parameters\n",
    "        show_details: If True, show breakdown by submodule\n",
    "    \"\"\"\n",
    "\n",
    "    total_params = count_parameters(model, trainable_only=trainable_only)\n",
    "    param_type = \"Trainable\" if trainable_only else \"Total\"\n",
    "\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"MODEL PARAMETER SUMMARY\")\n",
    "    print(f\"{'='*50}\")\n",
    "    print(f\"{param_type} Parameters: {total_params:,}\")\n",
    "    print(f\"Memory Usage: ~{total_params * 4 / 1024**2:.2f} MB (float32)\")\n",
    "\n",
    "    if show_details:\n",
    "        detailed_counts = count_parameters(model, trainable_only=trainable_only, detailed=True)\n",
    "\n",
    "        print(f\"\\nParameter Breakdown by Module:\")\n",
    "        print(f\"{'-'*50}\")\n",
    "        print(f\"{'Module Name':<30} {'Parameters':<15} {'%'}\")\n",
    "        print(f\"{'-'*50}\")\n",
    "\n",
    "        for module_name, param_count in detailed_counts.items():\n",
    "            if param_count > 0:  # Only show modules with parameters\n",
    "                percentage = (param_count / total_params) * 100\n",
    "                print(f\"{module_name:<30} {param_count:<15,} {percentage:>5.1f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2554d6e5",
   "metadata": {},
   "source": [
    "# Enc Dec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c30b4bc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/global/u1/p/pr4santh/Projects/SYMBA_SSM/model\n"
     ]
    }
   ],
   "source": [
    "# cd /global/homes/p/pr4santh/Projects/SYMBA_SSM/model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "da7796eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/global/u1/p/pr4santh/Projects/SYMBA_SSM/model/mamba_encdec.py\", line 15, in <module>\n",
      "    from .helpers.flash_cross_attention import FlashCrossAttentionWrapper\n",
      "ImportError: attempted relative import with no known parent package\n"
     ]
    }
   ],
   "source": [
    "!python mamba_encdec.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "abd8056c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/p/pr4santh/miniconda3/envs/ssm_env/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from model.mamba_encdec import MambaEncDec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ef5bb224",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_encoder_layers = 3\n",
    "num_decoder_layers = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "37c1d59e",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_layers = ['Mamba'] * 2 * (num_encoder_layers - 1) + ['FMHSA', 'FFN']\n",
    "decoder_layers = ['FXA', 'FFN'] + ['Mamba'] * 2 * (num_decoder_layers - 2) + ['FXA', 'FFN']\n",
    "# decoder_layers = ['Mamba'] * 2 * (num_decoder_layers - 1)\n",
    "\n",
    "\n",
    "# encoder_layers = ['FMHSA', 'FFN'] * (config.num_encoder_layers)\n",
    "# decoder_layers = ['FXA', 'FFN'] * (config.num_decoder_layers)\n",
    "\n",
    "mamba_config = {\n",
    "    \"enc_n_layer\": (num_encoder_layers - 1) * 2,\n",
    "    \"d_model\": 512,\n",
    "    \"dec_n_layer\": (num_decoder_layers - 2) * 2,\n",
    "    \"rms_norm\": True,\n",
    "    \"fused_add_norm\": True,\n",
    "    \"use_fast_path\": False,\n",
    "    \"encoder_layer_list\": encoder_layers,\n",
    "    \"decoder_layer_list\": decoder_layers,\n",
    "    # \"learning_rate\": config.learning_rate,\n",
    "    # \"warmup_steps\": config.warmup_steps,\n",
    "    # \"weight_decay\": config.weight_decay,\n",
    "    # \"devices\": config.devices\n",
    "}\n",
    "# mamba_config = {\n",
    "#     \"enc_n_layer\": config.num_encoder_layers,\n",
    "#     \"d_model\": config.d_model,\n",
    "#     \"n_layer\": config.n_layer,\n",
    "#     \"rms_norm\": config.rms_norm,\n",
    "#     \"fused_add_norm\": config.fused_add_norm,\n",
    "#     \"use_fast_path\": config.use_fast_path,\n",
    "#     \"learning_rate\": config.learning_rate,\n",
    "#     \"warmup_steps\": config.warmup_steps,\n",
    "#     \"weight_decay\": config.weight_decay,\n",
    "#     \"devices\": config.devices\n",
    "# }\n",
    "\n",
    "model = MambaEncDec(\n",
    "    **mamba_config,\n",
    "    config = mamba_config,\n",
    "    src_vocab_size=412,\n",
    "    tgt_vocab_size=39\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c4786348",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MambaEncDec(\n",
       "  (encoder): MixerModel(\n",
       "    (embedding): Embedding(412, 512)\n",
       "    (layers): ModuleList(\n",
       "      (0-3): 4 x Block(\n",
       "        (mixer): Mamba(\n",
       "          (in_proj): Linear(in_features=512, out_features=2048, bias=False)\n",
       "          (conv1d): Conv1d(1024, 1024, kernel_size=(4,), stride=(1,), padding=(3,), groups=1024)\n",
       "          (act): SiLU()\n",
       "          (x_proj): Linear(in_features=1024, out_features=64, bias=False)\n",
       "          (dt_proj): Linear(in_features=32, out_features=1024, bias=True)\n",
       "          (out_proj): Linear(in_features=1024, out_features=512, bias=False)\n",
       "        )\n",
       "        (norm): RMSNorm()\n",
       "      )\n",
       "    )\n",
       "    (norm_f): RMSNorm()\n",
       "  )\n",
       "  (decoder): MambaDecoder(\n",
       "    (backbone): MixerModel(\n",
       "      (embedding): Embedding(39, 512)\n",
       "      (layers): ModuleList(\n",
       "        (0): FlashCrossAttentionWrapper(\n",
       "          (attention): Attention(\n",
       "            (to_q): Linear(in_features=512, out_features=512, bias=False)\n",
       "            (to_k): Linear(in_features=512, out_features=512, bias=False)\n",
       "            (to_v): Linear(in_features=512, out_features=512, bias=False)\n",
       "            (split_q_heads): Rearrange('b n (h d) -> b h n d', h=8)\n",
       "            (split_k_heads): Rearrange('b n (h d) -> b h n d', d=64)\n",
       "            (split_v_heads): Rearrange('b n (h d) -> b h n d', d=64)\n",
       "            (merge_heads): Rearrange('b h n d -> b n (h d)')\n",
       "            (attend): Attend(\n",
       "              (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (to_out): Linear(in_features=512, out_features=512, bias=False)\n",
       "          )\n",
       "          (rel_pos): RelativePositionBias(\n",
       "            (relative_attention_bias): Embedding(32, 8)\n",
       "          )\n",
       "          (norm): RMSNorm()\n",
       "        )\n",
       "        (1): FeedForwardWrapper(\n",
       "          (norm): RMSNorm()\n",
       "          (mlp): GatedMlp(\n",
       "            (fc1): Linear(in_features=512, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (2-3): 2 x Block(\n",
       "          (mixer): Mamba(\n",
       "            (in_proj): Linear(in_features=512, out_features=2048, bias=False)\n",
       "            (conv1d): Conv1d(1024, 1024, kernel_size=(4,), stride=(1,), padding=(3,), groups=1024)\n",
       "            (act): SiLU()\n",
       "            (x_proj): Linear(in_features=1024, out_features=64, bias=False)\n",
       "            (dt_proj): Linear(in_features=32, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=512, bias=False)\n",
       "          )\n",
       "          (norm): RMSNorm()\n",
       "        )\n",
       "      )\n",
       "      (norm_f): RMSNorm()\n",
       "    )\n",
       "    (generator): Linear(in_features=512, out_features=39, bias=False)\n",
       "  )\n",
       "  (generator): Linear(in_features=512, out_features=39, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e4b187e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2654f384",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "MODEL PARAMETER SUMMARY\n",
      "==================================================\n",
      "Total Parameters: 14,603,520\n",
      "Memory Usage: ~55.71 MB (float32)\n",
      "\n",
      "Parameter Breakdown by Module:\n",
      "--------------------------------------------------\n",
      "Module Name                    Parameters      %\n",
      "--------------------------------------------------\n",
      "decoder.backbone.layers.1.mlp.fc1 2,101,248        14.4%\n",
      "decoder.backbone.layers.1.mlp.fc2 1,049,088         7.2%\n",
      "encoder.layers.0.mixer.in_proj 1,048,576         7.2%\n",
      "encoder.layers.1.mixer.in_proj 1,048,576         7.2%\n",
      "encoder.layers.2.mixer.in_proj 1,048,576         7.2%\n",
      "encoder.layers.3.mixer.in_proj 1,048,576         7.2%\n",
      "decoder.backbone.layers.2.mixer.in_proj 1,048,576         7.2%\n",
      "decoder.backbone.layers.3.mixer.in_proj 1,048,576         7.2%\n",
      "encoder.layers.0.mixer.out_proj 524,288           3.6%\n",
      "encoder.layers.1.mixer.out_proj 524,288           3.6%\n",
      "encoder.layers.2.mixer.out_proj 524,288           3.6%\n",
      "encoder.layers.3.mixer.out_proj 524,288           3.6%\n",
      "decoder.backbone.layers.2.mixer.out_proj 524,288           3.6%\n",
      "decoder.backbone.layers.3.mixer.out_proj 524,288           3.6%\n",
      "decoder.backbone.layers.0.attention.to_q 262,144           1.8%\n",
      "decoder.backbone.layers.0.attention.to_k 262,144           1.8%\n",
      "decoder.backbone.layers.0.attention.to_v 262,144           1.8%\n",
      "decoder.backbone.layers.0.attention.to_out 262,144           1.8%\n",
      "encoder.embedding              210,944           1.4%\n",
      "encoder.layers.0.mixer.x_proj  65,536            0.4%\n",
      "encoder.layers.1.mixer.x_proj  65,536            0.4%\n",
      "encoder.layers.2.mixer.x_proj  65,536            0.4%\n",
      "encoder.layers.3.mixer.x_proj  65,536            0.4%\n",
      "decoder.backbone.layers.2.mixer.x_proj 65,536            0.4%\n",
      "decoder.backbone.layers.3.mixer.x_proj 65,536            0.4%\n",
      "encoder.layers.0.mixer.dt_proj 33,792            0.2%\n",
      "encoder.layers.1.mixer.dt_proj 33,792            0.2%\n",
      "encoder.layers.2.mixer.dt_proj 33,792            0.2%\n",
      "encoder.layers.3.mixer.dt_proj 33,792            0.2%\n",
      "decoder.backbone.layers.2.mixer.dt_proj 33,792            0.2%\n",
      "decoder.backbone.layers.3.mixer.dt_proj 33,792            0.2%\n",
      "decoder.backbone.embedding     19,968            0.1%\n",
      "decoder.generator              19,968            0.1%\n",
      "encoder.layers.0.mixer         17,408            0.1%\n",
      "encoder.layers.1.mixer         17,408            0.1%\n",
      "encoder.layers.2.mixer         17,408            0.1%\n",
      "encoder.layers.3.mixer         17,408            0.1%\n",
      "decoder.backbone.layers.2.mixer 17,408            0.1%\n",
      "decoder.backbone.layers.3.mixer 17,408            0.1%\n",
      "encoder.layers.0.mixer.conv1d  5,120             0.0%\n",
      "encoder.layers.1.mixer.conv1d  5,120             0.0%\n",
      "encoder.layers.2.mixer.conv1d  5,120             0.0%\n",
      "encoder.layers.3.mixer.conv1d  5,120             0.0%\n",
      "decoder.backbone.layers.2.mixer.conv1d 5,120             0.0%\n",
      "decoder.backbone.layers.3.mixer.conv1d 5,120             0.0%\n",
      "encoder.layers.0.norm          512               0.0%\n",
      "encoder.layers.1.norm          512               0.0%\n",
      "encoder.layers.2.norm          512               0.0%\n",
      "encoder.layers.3.norm          512               0.0%\n",
      "encoder.norm_f                 512               0.0%\n",
      "decoder.backbone.layers.0.norm 512               0.0%\n",
      "decoder.backbone.layers.1.norm 512               0.0%\n",
      "decoder.backbone.layers.2.norm 512               0.0%\n",
      "decoder.backbone.layers.3.norm 512               0.0%\n",
      "decoder.backbone.norm_f        512               0.0%\n",
      "decoder.backbone.layers.0.rel_pos.relative_attention_bias 256               0.0%\n"
     ]
    }
   ],
   "source": [
    "print_parameter_summary(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "da9ec651",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MambaEncDec(\n",
       "  (encoder): MixerModel(\n",
       "    (embedding): Embedding(412, 512)\n",
       "    (layers): ModuleList(\n",
       "      (0-3): 4 x Block(\n",
       "        (mixer): Mamba(\n",
       "          (in_proj): Linear(in_features=512, out_features=2048, bias=False)\n",
       "          (conv1d): Conv1d(1024, 1024, kernel_size=(4,), stride=(1,), padding=(3,), groups=1024)\n",
       "          (act): SiLU()\n",
       "          (x_proj): Linear(in_features=1024, out_features=64, bias=False)\n",
       "          (dt_proj): Linear(in_features=32, out_features=1024, bias=True)\n",
       "          (out_proj): Linear(in_features=1024, out_features=512, bias=False)\n",
       "        )\n",
       "        (norm): RMSNorm()\n",
       "      )\n",
       "      (4): FlashSelfAttentionWrapper(\n",
       "        (rotary_pos_emb): RotaryEmbedding()\n",
       "        (attention): Attention(\n",
       "          (to_q): Linear(in_features=512, out_features=512, bias=False)\n",
       "          (to_k): Linear(in_features=512, out_features=512, bias=False)\n",
       "          (to_v): Linear(in_features=512, out_features=512, bias=False)\n",
       "          (split_q_heads): Rearrange('b n (h d) -> b h n d', h=8)\n",
       "          (split_k_heads): Rearrange('b n (h d) -> b h n d', d=64)\n",
       "          (split_v_heads): Rearrange('b n (h d) -> b h n d', d=64)\n",
       "          (merge_heads): Rearrange('b h n d -> b n (h d)')\n",
       "          (attend): Attend(\n",
       "            (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (to_out): Linear(in_features=512, out_features=512, bias=False)\n",
       "        )\n",
       "        (norm): RMSNorm()\n",
       "      )\n",
       "      (5): FeedForwardWrapper(\n",
       "        (norm): RMSNorm()\n",
       "        (mlp): GatedMlp(\n",
       "          (fc1): Linear(in_features=512, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (norm_f): RMSNorm()\n",
       "  )\n",
       "  (decoder): MambaDecoder(\n",
       "    (backbone): MixerModel(\n",
       "      (embedding): Embedding(39, 512)\n",
       "      (layers): ModuleList(\n",
       "        (0): FlashCrossAttentionWrapper(\n",
       "          (attention): Attention(\n",
       "            (to_q): Linear(in_features=512, out_features=512, bias=False)\n",
       "            (to_k): Linear(in_features=512, out_features=512, bias=False)\n",
       "            (to_v): Linear(in_features=512, out_features=512, bias=False)\n",
       "            (split_q_heads): Rearrange('b n (h d) -> b h n d', h=8)\n",
       "            (split_k_heads): Rearrange('b n (h d) -> b h n d', d=64)\n",
       "            (split_v_heads): Rearrange('b n (h d) -> b h n d', d=64)\n",
       "            (merge_heads): Rearrange('b h n d -> b n (h d)')\n",
       "            (attend): Attend(\n",
       "              (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (to_out): Linear(in_features=512, out_features=512, bias=False)\n",
       "          )\n",
       "          (rel_pos): RelativePositionBias(\n",
       "            (relative_attention_bias): Embedding(32, 8)\n",
       "          )\n",
       "          (norm): RMSNorm()\n",
       "        )\n",
       "        (1): FeedForwardWrapper(\n",
       "          (norm): RMSNorm()\n",
       "          (mlp): GatedMlp(\n",
       "            (fc1): Linear(in_features=512, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (2-5): 4 x Block(\n",
       "          (mixer): Mamba(\n",
       "            (in_proj): Linear(in_features=512, out_features=2048, bias=False)\n",
       "            (conv1d): Conv1d(1024, 1024, kernel_size=(4,), stride=(1,), padding=(3,), groups=1024)\n",
       "            (act): SiLU()\n",
       "            (x_proj): Linear(in_features=1024, out_features=64, bias=False)\n",
       "            (dt_proj): Linear(in_features=32, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=512, bias=False)\n",
       "          )\n",
       "          (norm): RMSNorm()\n",
       "        )\n",
       "        (6): FlashCrossAttentionWrapper(\n",
       "          (attention): Attention(\n",
       "            (to_q): Linear(in_features=512, out_features=512, bias=False)\n",
       "            (to_k): Linear(in_features=512, out_features=512, bias=False)\n",
       "            (to_v): Linear(in_features=512, out_features=512, bias=False)\n",
       "            (split_q_heads): Rearrange('b n (h d) -> b h n d', h=8)\n",
       "            (split_k_heads): Rearrange('b n (h d) -> b h n d', d=64)\n",
       "            (split_v_heads): Rearrange('b n (h d) -> b h n d', d=64)\n",
       "            (merge_heads): Rearrange('b h n d -> b n (h d)')\n",
       "            (attend): Attend(\n",
       "              (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (to_out): Linear(in_features=512, out_features=512, bias=False)\n",
       "          )\n",
       "          (rel_pos): RelativePositionBias(\n",
       "            (relative_attention_bias): Embedding(32, 8)\n",
       "          )\n",
       "          (norm): RMSNorm()\n",
       "        )\n",
       "        (7): FeedForwardWrapper(\n",
       "          (norm): RMSNorm()\n",
       "          (mlp): GatedMlp(\n",
       "            (fc1): Linear(in_features=512, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (norm_f): RMSNorm()\n",
       "    )\n",
       "    (generator): Linear(in_features=512, out_features=39, bias=False)\n",
       "  )\n",
       "  (generator): Linear(in_features=512, out_features=39, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7637ad15",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_layers = ['FMHSA', 'FFN'] * (num_encoder_layers)\n",
    "decoder_layers = ['FXA', 'FFN'] * (num_decoder_layers)\n",
    "\n",
    "\n",
    "# encoder_layers = ['FMHSA', 'FFN'] * (config.num_encoder_layers)\n",
    "# decoder_layers = ['FXA', 'FFN'] * (config.num_decoder_layers)\n",
    "\n",
    "mamba_config = {\n",
    "    \"enc_n_layer\": num_encoder_layers * 2,\n",
    "    \"d_model\": 512,\n",
    "    \"dec_n_layer\": num_decoder_layers * 2,\n",
    "    \"rms_norm\": True,\n",
    "    \"fused_add_norm\": True,\n",
    "    \"use_fast_path\": False,\n",
    "    \"encoder_layer_list\": encoder_layers,\n",
    "    \"decoder_layer_list\": decoder_layers,\n",
    "    # \"learning_rate\": config.learning_rate,\n",
    "    # \"warmup_steps\": config.warmup_steps,\n",
    "    # \"weight_decay\": config.weight_decay,\n",
    "    # \"devices\": config.devices\n",
    "}\n",
    "# mamba_config = {\n",
    "#     \"enc_n_layer\": config.num_encoder_layers,\n",
    "#     \"d_model\": config.d_model,\n",
    "#     \"n_layer\": config.n_layer,\n",
    "#     \"rms_norm\": config.rms_norm,\n",
    "#     \"fused_add_norm\": config.fused_add_norm,\n",
    "#     \"use_fast_path\": config.use_fast_path,\n",
    "#     \"learning_rate\": config.learning_rate,\n",
    "#     \"warmup_steps\": config.warmup_steps,\n",
    "#     \"weight_decay\": config.weight_decay,\n",
    "#     \"devices\": config.devices\n",
    "# }\n",
    "\n",
    "model = MambaEncDec(\n",
    "    **mamba_config,\n",
    "    config = mamba_config,\n",
    "    src_vocab_size=412,\n",
    "    tgt_vocab_size=39\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "560cdda0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "MODEL PARAMETER SUMMARY\n",
      "==================================================\n",
      "Total Parameters: 29,632,512\n",
      "Memory Usage: ~113.04 MB (float32)\n",
      "\n",
      "Parameter Breakdown by Module:\n",
      "--------------------------------------------------\n",
      "Module Name                    Parameters      %\n",
      "--------------------------------------------------\n",
      "encoder.layers.1.mlp.fc1       2,101,248         7.1%\n",
      "encoder.layers.3.mlp.fc1       2,101,248         7.1%\n",
      "encoder.layers.5.mlp.fc1       2,101,248         7.1%\n",
      "decoder.backbone.layers.1.mlp.fc1 2,101,248         7.1%\n",
      "decoder.backbone.layers.3.mlp.fc1 2,101,248         7.1%\n",
      "decoder.backbone.layers.5.mlp.fc1 2,101,248         7.1%\n",
      "decoder.backbone.layers.7.mlp.fc1 2,101,248         7.1%\n",
      "encoder.layers.1.mlp.fc2       1,049,088         3.5%\n",
      "encoder.layers.3.mlp.fc2       1,049,088         3.5%\n",
      "encoder.layers.5.mlp.fc2       1,049,088         3.5%\n",
      "decoder.backbone.layers.1.mlp.fc2 1,049,088         3.5%\n",
      "decoder.backbone.layers.3.mlp.fc2 1,049,088         3.5%\n",
      "decoder.backbone.layers.5.mlp.fc2 1,049,088         3.5%\n",
      "decoder.backbone.layers.7.mlp.fc2 1,049,088         3.5%\n",
      "encoder.layers.0.attention.to_q 262,144           0.9%\n",
      "encoder.layers.0.attention.to_k 262,144           0.9%\n",
      "encoder.layers.0.attention.to_v 262,144           0.9%\n",
      "encoder.layers.0.attention.to_out 262,144           0.9%\n",
      "encoder.layers.2.attention.to_q 262,144           0.9%\n",
      "encoder.layers.2.attention.to_k 262,144           0.9%\n",
      "encoder.layers.2.attention.to_v 262,144           0.9%\n",
      "encoder.layers.2.attention.to_out 262,144           0.9%\n",
      "encoder.layers.4.attention.to_q 262,144           0.9%\n",
      "encoder.layers.4.attention.to_k 262,144           0.9%\n",
      "encoder.layers.4.attention.to_v 262,144           0.9%\n",
      "encoder.layers.4.attention.to_out 262,144           0.9%\n",
      "decoder.backbone.layers.0.attention.to_q 262,144           0.9%\n",
      "decoder.backbone.layers.0.attention.to_k 262,144           0.9%\n",
      "decoder.backbone.layers.0.attention.to_v 262,144           0.9%\n",
      "decoder.backbone.layers.0.attention.to_out 262,144           0.9%\n",
      "decoder.backbone.layers.2.attention.to_q 262,144           0.9%\n",
      "decoder.backbone.layers.2.attention.to_k 262,144           0.9%\n",
      "decoder.backbone.layers.2.attention.to_v 262,144           0.9%\n",
      "decoder.backbone.layers.2.attention.to_out 262,144           0.9%\n",
      "decoder.backbone.layers.4.attention.to_q 262,144           0.9%\n",
      "decoder.backbone.layers.4.attention.to_k 262,144           0.9%\n",
      "decoder.backbone.layers.4.attention.to_v 262,144           0.9%\n",
      "decoder.backbone.layers.4.attention.to_out 262,144           0.9%\n",
      "decoder.backbone.layers.6.attention.to_q 262,144           0.9%\n",
      "decoder.backbone.layers.6.attention.to_k 262,144           0.9%\n",
      "decoder.backbone.layers.6.attention.to_v 262,144           0.9%\n",
      "decoder.backbone.layers.6.attention.to_out 262,144           0.9%\n",
      "encoder.embedding              210,944           0.7%\n",
      "decoder.backbone.embedding     19,968            0.1%\n",
      "decoder.generator              19,968            0.1%\n",
      "encoder.layers.0.norm          512               0.0%\n",
      "encoder.layers.1.norm          512               0.0%\n",
      "encoder.layers.2.norm          512               0.0%\n",
      "encoder.layers.3.norm          512               0.0%\n",
      "encoder.layers.4.norm          512               0.0%\n",
      "encoder.layers.5.norm          512               0.0%\n",
      "encoder.norm_f                 512               0.0%\n",
      "decoder.backbone.layers.0.norm 512               0.0%\n",
      "decoder.backbone.layers.1.norm 512               0.0%\n",
      "decoder.backbone.layers.2.norm 512               0.0%\n",
      "decoder.backbone.layers.3.norm 512               0.0%\n",
      "decoder.backbone.layers.4.norm 512               0.0%\n",
      "decoder.backbone.layers.5.norm 512               0.0%\n",
      "decoder.backbone.layers.6.norm 512               0.0%\n",
      "decoder.backbone.layers.7.norm 512               0.0%\n",
      "decoder.backbone.norm_f        512               0.0%\n",
      "decoder.backbone.layers.0.rel_pos.relative_attention_bias 256               0.0%\n",
      "decoder.backbone.layers.2.rel_pos.relative_attention_bias 256               0.0%\n",
      "decoder.backbone.layers.4.rel_pos.relative_attention_bias 256               0.0%\n",
      "decoder.backbone.layers.6.rel_pos.relative_attention_bias 256               0.0%\n"
     ]
    }
   ],
   "source": [
    "print_parameter_summary(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b574e0f",
   "metadata": {},
   "source": [
    "# Dec only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7fcb007f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python model/mamba_dec.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7b49fd1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/p/pr4santh/miniconda3/envs/ssm_env/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from model.mamba_dec import MambaMT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3be5c8dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "mamba_config = {\n",
    "    \"d_model\": 512,\n",
    "    \"n_layer\": 8,\n",
    "    \"rms_norm\": True,\n",
    "    \"fused_add_norm\": True,\n",
    "    \"pad_vocab_size_multiple\": 2\n",
    "    # \"use_fast_path\": False,\n",
    "}\n",
    "\n",
    "model = MambaMT(\n",
    "    **mamba_config,\n",
    "    config = mamba_config,\n",
    "    src_vocab_size=412,\n",
    "    tgt_vocab_size=48,\n",
    "    precision=\"bf16-mixed\"\n",
    "    # tgt_vocab_size=39,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9dbc7a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device='cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8ecd274b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MambaMT(\n",
       "  (model): MambaLMHeadModel(\n",
       "    (backbone): MixerModel(\n",
       "      (embedding): Embedding(416, 512)\n",
       "      (layers): ModuleList(\n",
       "        (0-7): 8 x Block(\n",
       "          (norm): RMSNorm()\n",
       "          (mixer): Mamba(\n",
       "            (in_proj): Linear(in_features=512, out_features=2048, bias=False)\n",
       "            (conv1d): Conv1d(1024, 1024, kernel_size=(4,), stride=(1,), padding=(3,), groups=1024)\n",
       "            (act): SiLU()\n",
       "            (x_proj): Linear(in_features=1024, out_features=64, bias=False)\n",
       "            (dt_proj): Linear(in_features=32, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=512, bias=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (norm_f): RMSNorm()\n",
       "    )\n",
       "    (lm_head): Linear(in_features=512, out_features=416, bias=False)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=512, out_features=48, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "40ad3bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "src = np.random.randint(low=0, high=418, size=5)\n",
    "tgt = np.random.randint(low=0, high=49, size=5)\n",
    "\n",
    "src_padding_mask = np.random.randint(low=0, high=2, size=len(src))\n",
    "# Generate a causal target mask\n",
    "# This is a lower triangular matrix of 1s, preventing the model from attending to future tokens.\n",
    "tgt_padding_mask = np.tril(np.ones((len(tgt), len(tgt)), dtype=int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f0d99d53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 1, 1])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src_padding_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d98c8000",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.39 s, sys: 322 ms, total: 1.71 s\n",
      "Wall time: 2.18 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "out = model.model.forward(input_ids = torch.tensor(src,device='cuda:0').unsqueeze(0), position_ids=None, inference_params=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "567bc625",
   "metadata": {},
   "outputs": [],
   "source": [
    "out2 = model.forward(input_ids = torch.tensor(src,device='cuda:0').unsqueeze(0), position_ids=None, inference_params=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dc06c9f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 5, 416]), torch.Size([1, 5, 48]))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.logits.shape, out2.logits.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72427867",
   "metadata": {},
   "source": [
    "# Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f1bb54a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/global/u1/p/pr4santh/Projects/SineKAN\n"
     ]
    }
   ],
   "source": [
    "cd /global/homes/p/pr4santh/Projects/SineKAN/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b1dfcbb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.model import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "73b34640",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_model = Model(\n",
    "    3, #config.num_encoder_layers,\n",
    "    4, #config.num_decoder_layers,\n",
    "    512, #config.embedding_size,\n",
    "    8, #config.nhead,\n",
    "    149, #config.src_voc_size,\n",
    "    94, #config.tgt_voc_size,\n",
    "    512, #config.ff_dims,\n",
    "    0.1, #config.dropout,\n",
    "    False, #config.is_pre_norm,\n",
    "    False, # config.is_kan,\n",
    "    device='cuda',# config.kan_ff_dims,\n",
    "    # config.kan_grid_size,\n",
    "    #config.device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "294cba32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "MODEL PARAMETER SUMMARY\n",
      "==================================================\n",
      "Total Parameters: 15,425,118\n",
      "Memory Usage: ~58.84 MB (float32)\n",
      "\n",
      "Parameter Breakdown by Module:\n",
      "--------------------------------------------------\n",
      "Module Name                    Parameters      %\n",
      "--------------------------------------------------\n",
      "transformer.encoder.layers.0.self_attn.q_proj 262,656           1.7%\n",
      "transformer.encoder.layers.0.self_attn.k_proj 262,656           1.7%\n",
      "transformer.encoder.layers.0.self_attn.v_proj 262,656           1.7%\n",
      "transformer.encoder.layers.0.self_attn.out_proj 262,656           1.7%\n",
      "transformer.encoder.layers.0.linear1 262,656           1.7%\n",
      "transformer.encoder.layers.0.linear2 262,656           1.7%\n",
      "transformer.encoder.layers.1.self_attn.q_proj 262,656           1.7%\n",
      "transformer.encoder.layers.1.self_attn.k_proj 262,656           1.7%\n",
      "transformer.encoder.layers.1.self_attn.v_proj 262,656           1.7%\n",
      "transformer.encoder.layers.1.self_attn.out_proj 262,656           1.7%\n",
      "transformer.encoder.layers.1.linear1 262,656           1.7%\n",
      "transformer.encoder.layers.1.linear2 262,656           1.7%\n",
      "transformer.encoder.layers.2.self_attn.q_proj 262,656           1.7%\n",
      "transformer.encoder.layers.2.self_attn.k_proj 262,656           1.7%\n",
      "transformer.encoder.layers.2.self_attn.v_proj 262,656           1.7%\n",
      "transformer.encoder.layers.2.self_attn.out_proj 262,656           1.7%\n",
      "transformer.encoder.layers.2.linear1 262,656           1.7%\n",
      "transformer.encoder.layers.2.linear2 262,656           1.7%\n",
      "transformer.decoder.layers.0.self_attn.q_proj 262,656           1.7%\n",
      "transformer.decoder.layers.0.self_attn.k_proj 262,656           1.7%\n",
      "transformer.decoder.layers.0.self_attn.v_proj 262,656           1.7%\n",
      "transformer.decoder.layers.0.self_attn.out_proj 262,656           1.7%\n",
      "transformer.decoder.layers.0.cross_attn.q_proj 262,656           1.7%\n",
      "transformer.decoder.layers.0.cross_attn.k_proj 262,656           1.7%\n",
      "transformer.decoder.layers.0.cross_attn.v_proj 262,656           1.7%\n",
      "transformer.decoder.layers.0.cross_attn.out_proj 262,656           1.7%\n",
      "transformer.decoder.layers.0.linear1 262,656           1.7%\n",
      "transformer.decoder.layers.0.linear2 262,656           1.7%\n",
      "transformer.decoder.layers.1.self_attn.q_proj 262,656           1.7%\n",
      "transformer.decoder.layers.1.self_attn.k_proj 262,656           1.7%\n",
      "transformer.decoder.layers.1.self_attn.v_proj 262,656           1.7%\n",
      "transformer.decoder.layers.1.self_attn.out_proj 262,656           1.7%\n",
      "transformer.decoder.layers.1.cross_attn.q_proj 262,656           1.7%\n",
      "transformer.decoder.layers.1.cross_attn.k_proj 262,656           1.7%\n",
      "transformer.decoder.layers.1.cross_attn.v_proj 262,656           1.7%\n",
      "transformer.decoder.layers.1.cross_attn.out_proj 262,656           1.7%\n",
      "transformer.decoder.layers.1.linear1 262,656           1.7%\n",
      "transformer.decoder.layers.1.linear2 262,656           1.7%\n",
      "transformer.decoder.layers.2.self_attn.q_proj 262,656           1.7%\n",
      "transformer.decoder.layers.2.self_attn.k_proj 262,656           1.7%\n",
      "transformer.decoder.layers.2.self_attn.v_proj 262,656           1.7%\n",
      "transformer.decoder.layers.2.self_attn.out_proj 262,656           1.7%\n",
      "transformer.decoder.layers.2.cross_attn.q_proj 262,656           1.7%\n",
      "transformer.decoder.layers.2.cross_attn.k_proj 262,656           1.7%\n",
      "transformer.decoder.layers.2.cross_attn.v_proj 262,656           1.7%\n",
      "transformer.decoder.layers.2.cross_attn.out_proj 262,656           1.7%\n",
      "transformer.decoder.layers.2.linear1 262,656           1.7%\n",
      "transformer.decoder.layers.2.linear2 262,656           1.7%\n",
      "transformer.decoder.layers.3.self_attn.q_proj 262,656           1.7%\n",
      "transformer.decoder.layers.3.self_attn.k_proj 262,656           1.7%\n",
      "transformer.decoder.layers.3.self_attn.v_proj 262,656           1.7%\n",
      "transformer.decoder.layers.3.self_attn.out_proj 262,656           1.7%\n",
      "transformer.decoder.layers.3.cross_attn.q_proj 262,656           1.7%\n",
      "transformer.decoder.layers.3.cross_attn.k_proj 262,656           1.7%\n",
      "transformer.decoder.layers.3.cross_attn.v_proj 262,656           1.7%\n",
      "transformer.decoder.layers.3.cross_attn.out_proj 262,656           1.7%\n",
      "transformer.decoder.layers.3.linear1 262,656           1.7%\n",
      "transformer.decoder.layers.3.linear2 262,656           1.7%\n",
      "src_tok_emb.embedding          76,288            0.5%\n",
      "generator                      48,222            0.3%\n",
      "tgt_tok_emb.embedding          48,128            0.3%\n",
      "transformer.encoder.layers.0.norm1 1,024             0.0%\n",
      "transformer.encoder.layers.0.norm2 1,024             0.0%\n",
      "transformer.encoder.layers.1.norm1 1,024             0.0%\n",
      "transformer.encoder.layers.1.norm2 1,024             0.0%\n",
      "transformer.encoder.layers.2.norm1 1,024             0.0%\n",
      "transformer.encoder.layers.2.norm2 1,024             0.0%\n",
      "transformer.decoder.layers.0.norm1 1,024             0.0%\n",
      "transformer.decoder.layers.0.norm2 1,024             0.0%\n",
      "transformer.decoder.layers.0.norm3 1,024             0.0%\n",
      "transformer.decoder.layers.1.norm1 1,024             0.0%\n",
      "transformer.decoder.layers.1.norm2 1,024             0.0%\n",
      "transformer.decoder.layers.1.norm3 1,024             0.0%\n",
      "transformer.decoder.layers.2.norm1 1,024             0.0%\n",
      "transformer.decoder.layers.2.norm2 1,024             0.0%\n",
      "transformer.decoder.layers.2.norm3 1,024             0.0%\n",
      "transformer.decoder.layers.3.norm1 1,024             0.0%\n",
      "transformer.decoder.layers.3.norm2 1,024             0.0%\n",
      "transformer.decoder.layers.3.norm3 1,024             0.0%\n"
     ]
    }
   ],
   "source": [
    "print_parameter_summary(t_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2166dd63",
   "metadata": {},
   "source": [
    "# misc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "318a9fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device='cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2f46fd01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MambaEncDec(\n",
       "  (encoder): MixerModel(\n",
       "    (embedding): Embedding(300, 512)\n",
       "    (layers): ModuleList(\n",
       "      (0-3): 4 x Block(\n",
       "        (mixer): Mamba(\n",
       "          (in_proj): Linear(in_features=512, out_features=2048, bias=False)\n",
       "          (conv1d): Conv1d(1024, 1024, kernel_size=(4,), stride=(1,), padding=(3,), groups=1024)\n",
       "          (act): SiLU()\n",
       "          (x_proj): Linear(in_features=1024, out_features=64, bias=False)\n",
       "          (dt_proj): Linear(in_features=32, out_features=1024, bias=True)\n",
       "          (out_proj): Linear(in_features=1024, out_features=512, bias=False)\n",
       "        )\n",
       "        (norm): RMSNorm()\n",
       "      )\n",
       "    )\n",
       "    (norm_f): RMSNorm()\n",
       "  )\n",
       "  (decoder): MambaDecoder(\n",
       "    (backbone): MixerModel(\n",
       "      (embedding): Embedding(51, 512)\n",
       "      (layers): ModuleList(\n",
       "        (0): Block(\n",
       "          (mixer): Mamba(\n",
       "            (in_proj): Linear(in_features=512, out_features=2048, bias=False)\n",
       "            (conv1d): Conv1d(1024, 1024, kernel_size=(4,), stride=(1,), padding=(3,), groups=1024)\n",
       "            (act): SiLU()\n",
       "            (x_proj): Linear(in_features=1024, out_features=64, bias=False)\n",
       "            (dt_proj): Linear(in_features=32, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=512, bias=False)\n",
       "          )\n",
       "          (norm): RMSNorm()\n",
       "        )\n",
       "        (1): FlashCrossAttentionWrapper(\n",
       "          (attention): Attention(\n",
       "            (to_q): Linear(in_features=512, out_features=512, bias=False)\n",
       "            (to_k): Linear(in_features=512, out_features=512, bias=False)\n",
       "            (to_v): Linear(in_features=512, out_features=512, bias=False)\n",
       "            (split_q_heads): Rearrange('b n (h d) -> b h n d', h=8)\n",
       "            (split_k_heads): Rearrange('b n (h d) -> b h n d', d=64)\n",
       "            (split_v_heads): Rearrange('b n (h d) -> b h n d', d=64)\n",
       "            (merge_heads): Rearrange('b h n d -> b n (h d)')\n",
       "            (attend): Attend(\n",
       "              (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (to_out): Linear(in_features=512, out_features=512, bias=False)\n",
       "          )\n",
       "          (rel_pos): RelativePositionBias(\n",
       "            (relative_attention_bias): Embedding(32, 8)\n",
       "          )\n",
       "          (norm): RMSNorm()\n",
       "        )\n",
       "        (2): FeedForwardWrapper(\n",
       "          (norm): RMSNorm()\n",
       "          (mlp): GatedMlp(\n",
       "            (fc1): Linear(in_features=512, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (3): Block(\n",
       "          (mixer): Mamba(\n",
       "            (in_proj): Linear(in_features=512, out_features=2048, bias=False)\n",
       "            (conv1d): Conv1d(1024, 1024, kernel_size=(4,), stride=(1,), padding=(3,), groups=1024)\n",
       "            (act): SiLU()\n",
       "            (x_proj): Linear(in_features=1024, out_features=64, bias=False)\n",
       "            (dt_proj): Linear(in_features=32, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=512, bias=False)\n",
       "          )\n",
       "          (norm): RMSNorm()\n",
       "        )\n",
       "        (4): FlashCrossAttentionWrapper(\n",
       "          (attention): Attention(\n",
       "            (to_q): Linear(in_features=512, out_features=512, bias=False)\n",
       "            (to_k): Linear(in_features=512, out_features=512, bias=False)\n",
       "            (to_v): Linear(in_features=512, out_features=512, bias=False)\n",
       "            (split_q_heads): Rearrange('b n (h d) -> b h n d', h=8)\n",
       "            (split_k_heads): Rearrange('b n (h d) -> b h n d', d=64)\n",
       "            (split_v_heads): Rearrange('b n (h d) -> b h n d', d=64)\n",
       "            (merge_heads): Rearrange('b h n d -> b n (h d)')\n",
       "            (attend): Attend(\n",
       "              (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (to_out): Linear(in_features=512, out_features=512, bias=False)\n",
       "          )\n",
       "          (rel_pos): RelativePositionBias(\n",
       "            (relative_attention_bias): Embedding(32, 8)\n",
       "          )\n",
       "          (norm): RMSNorm()\n",
       "        )\n",
       "        (5): FeedForwardWrapper(\n",
       "          (norm): RMSNorm()\n",
       "          (mlp): GatedMlp(\n",
       "            (fc1): Linear(in_features=512, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (norm_f): RMSNorm()\n",
       "    )\n",
       "    (lm_head): Linear(in_features=512, out_features=51, bias=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e1feafbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2bd52a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "del model\n",
    "import torch\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9d4d48d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ssm_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
